{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Library\\Downloads\\Documents\\School\\SUPSI_23-24\\hackathon_2\\project\\venv\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>proc_text</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>majority_vote</th>\n",
       "      <th>roundID</th>\n",
       "      <th>...</th>\n",
       "      <th>nonflu</th>\n",
       "      <th>filler</th>\n",
       "      <th>AllPunc</th>\n",
       "      <th>Period</th>\n",
       "      <th>Comma</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>OtherP</th>\n",
       "      <th>Emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuck you china. I was 2 years clear of severe ...</td>\n",
       "      <td>Fuck you china. I was 2 years clear of severe ...</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>Round1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.92</td>\n",
       "      <td>7.69</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.85</td>\n",
       "      <td>11.54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feeling so off today and I can’t tell if this ...</td>\n",
       "      <td>Feeling so off today and I can’t tell if this ...</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>Round1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good lord people we need to stop having people...</td>\n",
       "      <td>Good lord people we need to stop having people...</td>\n",
       "      <td>PP</td>\n",
       "      <td>UN</td>\n",
       "      <td>PP</td>\n",
       "      <td>PO</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>Round1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.05</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.76</td>\n",
       "      <td>9.52</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm telling yall, Chill the fuck out!! This Vi...</td>\n",
       "      <td>I'm telling yall, Chill the fuck out!! This Vi...</td>\n",
       "      <td>PO</td>\n",
       "      <td>PO</td>\n",
       "      <td>PO</td>\n",
       "      <td>PO</td>\n",
       "      <td>PO</td>\n",
       "      <td>PP</td>\n",
       "      <td>PO</td>\n",
       "      <td>Round1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.21</td>\n",
       "      <td>4.65</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.26</td>\n",
       "      <td>2.33</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Episode of #CoronaVirus panic. Man took his gl...</td>\n",
       "      <td>Episode of #CoronaVirus panic. Man took his gl...</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>Round1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>20.69</td>\n",
       "      <td>10.34</td>\n",
       "      <td>5.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Fuck you china. I was 2 years clear of severe ...   \n",
       "1  Feeling so off today and I can’t tell if this ...   \n",
       "2  Good lord people we need to stop having people...   \n",
       "3  I'm telling yall, Chill the fuck out!! This Vi...   \n",
       "4  Episode of #CoronaVirus panic. Man took his gl...   \n",
       "\n",
       "                                           proc_text  A1  A2  A3  A4  A5  A6  \\\n",
       "0  Fuck you china. I was 2 years clear of severe ...  PP  PP  PP  PP  PP  PP   \n",
       "1  Feeling so off today and I can’t tell if this ...  PP  PP  PP  PP  PP  PP   \n",
       "2  Good lord people we need to stop having people...  PP  UN  PP  PO  PP  PP   \n",
       "3  I'm telling yall, Chill the fuck out!! This Vi...  PO  PO  PO  PO  PO  PP   \n",
       "4  Episode of #CoronaVirus panic. Man took his gl...  PP  PP  PP  PP  PP  PP   \n",
       "\n",
       "  majority_vote roundID  ...  nonflu  filler  AllPunc  Period  Comma  QMark  \\\n",
       "0            PP  Round1  ...     0.0    0.00    26.92    7.69   3.85    0.0   \n",
       "1            PP  Round1  ...     0.0    0.00    28.00   12.00   0.00    0.0   \n",
       "2            PP  Round1  ...     0.0    0.00    19.05    4.76   0.00    0.0   \n",
       "3            PO  Round1  ...     0.0    0.00    37.21    4.65   2.33    0.0   \n",
       "4            PP  Round1  ...     0.0    1.72    20.69   10.34   5.17    0.0   \n",
       "\n",
       "   Exclam  Apostro  OtherP  Emoji  \n",
       "0    0.00     3.85   11.54    0.0  \n",
       "1    0.00     8.00    8.00   16.0  \n",
       "2    0.00     4.76    9.52    0.0  \n",
       "3   23.26     2.33    4.65    0.0  \n",
       "4    0.00     3.45    1.72    0.0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'data/r1_r2_annotations_liwc_h.xlsx'\n",
    "dfh = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "\n",
    "dfh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text' 'proc_text' 'A1' 'A2' 'A3' 'A4' 'A5' 'A6' 'majority_vote'\n",
      " 'roundID' 'Segment' 'WC' 'Analytic' 'Clout' 'Authentic' 'Tone' 'WPS'\n",
      " 'BigWords' 'Dic' 'Linguistic' 'function' 'pronoun' 'ppron' 'i' 'we' 'you'\n",
      " 'shehe' 'they' 'ipron' 'det' 'article' 'number' 'prep' 'auxverb' 'adverb'\n",
      " 'conj' 'negate' 'verb' 'adj' 'quantity' 'Drives' 'affiliation' 'achieve'\n",
      " 'power' 'Cognition' 'allnone' 'cogproc' 'insight' 'cause' 'discrep'\n",
      " 'tentat' 'certitude' 'differ' 'memory' 'Affect' 'tone_pos' 'tone_neg'\n",
      " 'emotion' 'emo_pos' 'emo_neg' 'emo_anx' 'emo_anger' 'emo_sad' 'swear'\n",
      " 'Social' 'socbehav' 'prosocial' 'polite' 'conflict' 'moral' 'comm'\n",
      " 'socrefs' 'family' 'friend' 'female' 'male' 'Culture' 'politic'\n",
      " 'ethnicity' 'tech' 'Lifestyle' 'leisure' 'home' 'work' 'money' 'relig'\n",
      " 'Physical' 'health' 'illness' 'wellness' 'mental' 'substances' 'sexual'\n",
      " 'food' 'death' 'need' 'want' 'acquire' 'lack' 'fulfill' 'fatigue'\n",
      " 'reward' 'risk' 'curiosity' 'allure' 'Perception' 'attention' 'motion'\n",
      " 'space' 'visual' 'auditory' 'feeling' 'time' 'focuspast' 'focuspresent'\n",
      " 'focusfuture' 'Conversation' 'netspeak' 'assent' 'nonflu' 'filler'\n",
      " 'AllPunc' 'Period' 'Comma' 'QMark' 'Exclam' 'Apostro' 'OtherP' 'Emoji']\n"
     ]
    }
   ],
   "source": [
    "print(dfh.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfh.drop(['A1','A2','A3','A4','A5','A6'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_vote\n",
      "PO    160\n",
      "UN     98\n",
      "PP     95\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['text', 'proc_text', 'majority_vote', 'roundID', 'Segment', 'WC',\n",
       "       'Analytic', 'Clout', 'Authentic', 'Tone', 'WPS', 'BigWords', 'Dic',\n",
       "       'Linguistic', 'function', 'pronoun', 'ppron', 'i', 'we', 'you',\n",
       "       'shehe', 'they', 'ipron', 'det', 'article', 'number', 'prep',\n",
       "       'auxverb', 'adverb', 'conj', 'negate', 'verb', 'adj', 'quantity',\n",
       "       'Drives', 'affiliation', 'achieve', 'power', 'Cognition',\n",
       "       'allnone', 'cogproc', 'insight', 'cause', 'discrep', 'tentat',\n",
       "       'certitude', 'differ', 'memory', 'Affect', 'tone_pos', 'tone_neg',\n",
       "       'emotion', 'emo_pos', 'emo_neg', 'emo_anx', 'emo_anger', 'emo_sad',\n",
       "       'swear', 'Social', 'socbehav', 'prosocial', 'polite', 'conflict',\n",
       "       'moral', 'comm', 'socrefs', 'family', 'friend', 'female', 'male',\n",
       "       'Culture', 'politic', 'ethnicity', 'tech', 'Lifestyle', 'leisure',\n",
       "       'home', 'work', 'money', 'relig', 'Physical', 'health', 'illness',\n",
       "       'wellness', 'mental', 'substances', 'sexual', 'food', 'death',\n",
       "       'need', 'want', 'acquire', 'lack', 'fulfill', 'fatigue', 'reward',\n",
       "       'risk', 'curiosity', 'allure', 'Perception', 'attention', 'motion',\n",
       "       'space', 'visual', 'auditory', 'feeling', 'time', 'focuspast',\n",
       "       'focuspresent', 'focusfuture', 'Conversation', 'netspeak',\n",
       "       'assent', 'nonflu', 'filler', 'AllPunc', 'Period', 'Comma',\n",
       "       'QMark', 'Exclam', 'Apostro', 'OtherP', 'Emoji'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfh = dfh[dfh['majority_vote'] != \"NoMajority\"]\n",
    "dfh.reset_index(drop=True, inplace=True)\n",
    "print(dfh.majority_vote.value_counts())\n",
    "dfh.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dfh['majority_vote']\n",
    "dfh.drop(['majority_vote'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfh[\"proc_text\"], target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorizing the tweets\n",
    "# vectorizer = CountVectorizer(stop_words='english')\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PO' 'PO' 'UN' 'PO' 'PO' 'PO' 'PP' 'PO' 'PO' 'PP' 'PO' 'PO' 'PP' 'PO'\n",
      " 'PP' 'PO' 'PO' 'PO' 'PO' 'PO' 'PO' 'PO' 'PO' 'PO' 'PP' 'PP' 'PP' 'PO'\n",
      " 'PO' 'PO' 'PP' 'PO' 'PO' 'PO' 'PO' 'PO' 'PO' 'PO' 'PP' 'PO' 'PO' 'PO'\n",
      " 'PO' 'PO' 'PO' 'PO' 'PP' 'PO' 'PP' 'UN' 'PO' 'PO' 'PO' 'PO' 'UN' 'PO'\n",
      " 'PO' 'PP' 'PO' 'PO' 'PO' 'PO' 'PO' 'PP' 'PP' 'PO' 'PO' 'PO' 'UN' 'PO'\n",
      " 'PO']\n",
      "Model Accuracy: 0.5774647887323944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_counts, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_counts)\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
